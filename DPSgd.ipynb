{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0uLpRj+9ebNevkj0HNzvx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghosh-sarbajit/DifferentialPrivacy/blob/main/DPSgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uisKALJk-pAO"
      },
      "outputs": [],
      "source": [
        "!pip install opacus\n",
        "!pip install opendp==0.11\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 9 Differentially Private Machine Learning (219p)"
      ],
      "metadata": {
        "id": "fCFeCh6u3icD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentially Private Gradient\n"
      ],
      "metadata": {
        "id": "Z76n2yn63ie1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opendp.prelude as dp"
      ],
      "metadata": {
        "id": "2NIB12aRTtrF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_nabla_loss_i(w):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    w_0, w_1 = w\n",
        "    def f_compute_grads(data):\n",
        "        x, y = data[np.newaxis].T\n",
        "        y_hat = w_0 + w_1 * x # forward pass y^ = f(x)\n",
        "        return (y_hat - y) * np.column_stack([np.ones(x.size), x])\n",
        "    space = dp.numpy.array2_domain(T=float), dp.symmetric_distance()\n",
        "    return dp.t.make_user_transformation(\n",
        "        *space, *space, f_compute_grads,\n",
        "        stability_map=lambda b_in: b_in)"
      ],
      "metadata": {
        "id": "vRQzb1fOTCoZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 100_000\n",
        "# public metadata\n",
        "# \"load\" the data\n",
        "x = np.random.uniform(-5, 5, size=N)\n",
        "y = 3 + 2 * x + np.random.normal(size=x.size)\n",
        "data = np.column_stack((x, y))\n",
        "max_contributions = 1"
      ],
      "metadata": {
        "id": "JYmIJRgST79u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model hyperparameters\n",
        "w = np.array([0.0, 0.0]) # initial choice of params\n",
        "gamma, num_steps = 0.3, 20\n",
        "norm = 2. # assumes most grads have magnitude lte 2\n",
        "noise_std = 100."
      ],
      "metadata": {
        "id": "_RjFDR8oaXEK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHAPTER 3 Stable Transformations 79p\n",
        "def make_np_sum(norm, p, origin=None):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    assert norm >= 0, \"norm must not be negative\"\n",
        "    # assume the origin is at zero if not specified\n",
        "    origin = 0.0 if origin is None else origin\n",
        "    #    C = ||O||_p    + R\n",
        "    constant = np.linalg.norm(np.atleast_1d(origin), ord=p) + norm\n",
        "    return dp.t.make_user_transformation(input_domain=dp.numpy.array2_domain(norm=norm, p=p, origin=origin),\n",
        "        input_metric=dp.symmetric_distance(),\n",
        "        output_domain=dp.vector_domain(dp.atom_domain(T=float)),\n",
        "        output_metric={1: dp.l1_distance, 2: dp.l2_distance}[p](T=float),\n",
        "        function=lambda data: data.sum(axis=0),\n",
        "        stability_map=lambda b_in: b_in * constant)"
      ],
      "metadata": {
        "id": "AFELEnI8vWXq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHAPTER 3 Stable Transformations 80p\n",
        "def make_np_clamp(norm, p, origin=None):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    assert norm >= 0., \"norm must not be negative\"\n",
        "    # assume the origin is at zero if not specified\n",
        "    origin = 0.0 if origin is None else origin\n",
        "\n",
        "    def clamp_row_norms(data):\n",
        "        data = data.copy()\n",
        "        # shift the data around zero\n",
        "        data -= origin\n",
        "\n",
        "        # compute the p-norm of each row\n",
        "        row_norms = np.linalg.norm(data, ord=p, axis=1, keepdims=True)\n",
        "        # scale each row down to have norm at most 1\n",
        "        data /= np.maximum(row_norms / norm, 1)\n",
        "\n",
        "        # shift the normed data around zero back to `origin`\n",
        "        data += origin\n",
        "        return data\n",
        "\n",
        "    return dp.t.make_user_transformation(\n",
        "    input_domain= dp.numpy.array2_domain (T=float), # input data is unconstrained\n",
        "    input_metric=dp.symmetric_distance(),\n",
        "    output_domain=dp.numpy.array2_domain(norm=norm, p=p, origin=origin),\n",
        "    output_metric=dp.symmetric_distance(),\n",
        "    function=clamp_row_norms,\n",
        "    stability_map=lambda b_in: b_in) # norm clamping is 1-stable row-by-row"
      ],
      "metadata": {
        "id": "WFDnEPoWvpIL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/opendp/opendp/discussions/304\n",
        "from opendp.mod import enable_features\n",
        "enable_features(\"contrib\")\n",
        "enable_features(\"floating-point\")\n",
        "enable_features(\"honest-but-curious\")"
      ],
      "metadata": {
        "id": "M-YLZy9syO3G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_meas = make_np_clamp(norm, p=2) >> \\\n",
        "    make_np_sum(norm, p=2) >> \\\n",
        "    dp.m.then_gaussian(scale=noise_std) >> \\\n",
        "    np.array # a postprocessor- load into a numpy array"
      ],
      "metadata": {
        "id": "aYjhTzSyaRKg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meas_comp = dp.c.make_sequential_composition(\n",
        "    input_domain=sum_meas.input_domain,\n",
        "    input_metric=sum_meas.input_metric,\n",
        "    output_measure=dp.zero_concentrated_divergence(T=float),\n",
        "    d_in=max_contributions,\n",
        "    d_mids=[sum_meas.map(max_contributions)] * num_steps\n",
        ")\n",
        "# qbl is an instance of the compositor that allows up to `num_steps` queries\n",
        "qbl = meas_comp(data)\n",
        "# now the only way to access the data is through the compositor\n",
        "del data"
      ],
      "metadata": {
        "id": "Y-QQrS3UaRUw",
        "outputId": "7dded801-2f8b-4d6b-860c-7dcb66819745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-d98aa9d43849>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# qbl is an instance of the compositor that allows up to `num_steps` queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mqbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeas_comp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# now the only way to access the data is through the compositor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(meas_comp.map(max_contributions)) # -> 0.004 = ρ\n",
        "εδ_curve = dp.c.make_zCDP_to_approxDP(meas_comp).map(max_contributions)\n",
        "print(εδ_curve.epsilon(1e-8)) # -> (0.4659, 1e-8) = (ε, δ)"
      ],
      "metadata": {
        "id": "mnAeC47Y2FYn",
        "outputId": "36a24bae-928a-4cd5-9e39-20c2922cf61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.004000000000000002\n",
            "0.46596519652756707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(num_steps):\n",
        "    # make a mechanism that computes the gradient\n",
        "    meas_nabla_loss = make_nabla_loss_i(w) >> sum_meas\n",
        "    # privately release the gradient by querying the compositor\n",
        "    w -= gamma * 2 / N * qbl(meas_nabla_loss)"
      ],
      "metadata": {
        "id": "vUO8FnQOa1Rk",
        "outputId": "a8d4ff67-1d5c-4188-bfd6-4760eaee95d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'opendp.prelude' has no attribute 'np_array2_domain'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-885fc43e7920>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# make a mechanism that computes the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmeas_nabla_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_nabla_loss_i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0msum_meas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# privately release the gradient by querying the compositor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mqbl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeas_nabla_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c322ff0261c2>\u001b[0m in \u001b[0;36mmake_nabla_loss_i\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# forward pass y^ = f(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_array2_domain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymmetric_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     return dp.t.make_user_transformation(\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_compute_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'opendp.prelude' has no attribute 'np_array2_domain'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(num_steps):\n",
        "    # make a mechanism that computes the gradient\n",
        "    meas_nabla_loss = make_nabla_loss_i(w) >> sum_meas\n",
        "    # privately release the gradient by querying the compositor\n",
        "    w -= gamma * 2 / N * qbl(meas_nabla_loss)"
      ],
      "metadata": {
        "id": "-xwLv0S6aRXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"params:\", w) # ~> [3.00183246 1.97430499]"
      ],
      "metadata": {
        "id": "vwDz97vjaRaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Batching (DP-SGD)"
      ],
      "metadata": {
        "id": "fD5WnkeMaQZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, \\\n",
        "OrdinalEncoder, Normalizer\n",
        "from opacus import PrivacyEngine"
      ],
      "metadata": {
        "id": "ROc1yj9GKAqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdultDataSet(Dataset):\n",
        "    def __init__(self, adult_data_file):\n",
        "    header = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship',\n",
        "    'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income']\n",
        "    df = pd.read_csv(adult_data_file, header=None, names=header,\n",
        "    sep=',\\\\s', na_values=['?'], engine='python')\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['income'] = df['income'].apply(lambda x: x.replace('.', ''))\n",
        "    categorical_columns = ['workclass', 'education', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'sex',\n",
        "    'native_country']\n",
        "    numerical_columns = ['age', 'capital_gain',\n",
        "    'capital_loss', 'hours_per_week']\n",
        "    column_transformer = make_column_transformer(\n",
        "    (OrdinalEncoder(), categorical_columns),\n",
        "    (StandardScaler(), numerical_columns),\n",
        "    )\n",
        "    self.y = LabelEncoder().fit_transform(df['income']).astype(float)\n",
        "    self.X = column_transformer.fit_transform(df)\n",
        "    self.X = Normalizer().fit_transform(self.X)\n",
        "    def __len__(self):\n",
        "    return len(self.y)"
      ],
      "metadata": {
        "id": "T-R9AzXtRA9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}