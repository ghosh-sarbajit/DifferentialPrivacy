{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0ftEj7WMMikKt9zDbxcPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghosh-sarbajit/DifferentialPrivacy/blob/main/DPSgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uisKALJk-pAO"
      },
      "outputs": [],
      "source": [
        "!pip install opacus\n",
        "!pip install opendp\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 9 Differentially Private Machine Learning"
      ],
      "metadata": {
        "id": "fCFeCh6u3icD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ":# Differentially Private Gradient Descent (DP-GD)\n"
      ],
      "metadata": {
        "id": "Z76n2yn63ie1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opendp.prelude as dp"
      ],
      "metadata": {
        "id": "2NIB12aRTtrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_nabla_loss_i(w):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    w_0, w_1 = w\n",
        "    def f_compute_grads(data):\n",
        "        x, y = data[np.newaxis].T\n",
        "        y_hat = w_0 + w_1 * x # forward pass y^ = f(x)\n",
        "        return (y_hat - y) * np.column_stack([np.ones(x.size), x])\n",
        "    space = dp.np_array2_domain(T=float), dp.symmetric_distance()\n",
        "    return dp.t.make_user_transformation(\n",
        "        *space, *space, f_compute_grads,\n",
        "        stability_map=lambda b_in: b_in)"
      ],
      "metadata": {
        "id": "vRQzb1fOTCoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 100_000\n",
        "# public metadata\n",
        "# \"load\" the data\n",
        "x = np.random.uniform(-5, 5, size=N)\n",
        "y = 3 + 2 * x + np.random.normal(size=x.size)\n",
        "data = np.column_stack((x, y))\n",
        "max_contributions = 1"
      ],
      "metadata": {
        "id": "JYmIJRgST79u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model hyperparameters\n",
        "w = np.array([0.0, 0.0]) # initial choice of params\n",
        "gamma, num_steps = 0.3, 20\n",
        "norm = 2. # assumes most grads have magnitude lte 2\n",
        "noise_std = 100."
      ],
      "metadata": {
        "id": "_RjFDR8oaXEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_meas = make_np_clamp(norm, p=2) >> \\\n",
        "    make_np_sum(norm, p=2) >> \\\n",
        "    dp.m.then_gaussian(scale=noise_std) >> \\\n",
        "    np.array # a postprocessor- load into a numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "aYjhTzSyaRKg",
        "outputId": "7f99b123-c4b1-4689-b25a-f035124de616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'make_np_clamp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d95129503140>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msum_meas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np_clamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmake_np_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthen_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_std\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>>\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;31m# a postprocessor- load into a numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_np_clamp' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meas_comp = dp.c.make_sequential_composition(\n",
        "input_domain=sum_meas.input_domain,\n",
        "input_metric=sum_meas.input_metric,\n",
        "output_measure=dp.zero_concentrated_divergence(T=float),\n",
        "d_in=max_contributions,\n",
        "d_mids=[sum_meas.map(max_contributions)] * num_steps\n",
        ")\n",
        "# qbl is an instance of the compositor that allows up to `num_steps` queries\n",
        "qbl = meas_comp(data)\n",
        "# now the only way to access the data is through the compositor\n",
        "del data"
      ],
      "metadata": {
        "id": "Y-QQrS3UaRUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(meas_comp.map(max_contributions)) # -> 0.004 = ρ\n",
        "εδ_curve = dp.c.make_zCDP_to_approxDP(meas_comp).map(max_contributions)\n",
        "print(εδ_curve.epsilon(1e-8))\n",
        "# -> (0.4659, 1e-8) = (ε, δ)"
      ],
      "metadata": {
        "id": "vUO8FnQOa1Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(num_steps):\n",
        "    # make a mechanism that computes the gradient\n",
        "    meas_nabla_loss = make_nabla_loss_i(w) >> sum_meas\n",
        "    # privately release the gradient by querying the compositor\n",
        "    w -= gamma * 2 / N * qbl(meas_nabla_loss)"
      ],
      "metadata": {
        "id": "-xwLv0S6aRXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"params:\", w) # ~> [3.00183246 1.97430499]"
      ],
      "metadata": {
        "id": "vwDz97vjaRaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Batching (DP-SGD)"
      ],
      "metadata": {
        "id": "fD5WnkeMaQZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, \\\n",
        "OrdinalEncoder, Normalizer\n",
        "from opacus import PrivacyEngine"
      ],
      "metadata": {
        "id": "ROc1yj9GKAqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdultDataSet(Dataset):\n",
        "    def __init__(self, adult_data_file):\n",
        "    header = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship',\n",
        "    'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income']\n",
        "    df = pd.read_csv(adult_data_file, header=None, names=header,\n",
        "    sep=',\\\\s', na_values=['?'], engine='python')\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['income'] = df['income'].apply(lambda x: x.replace('.', ''))\n",
        "    categorical_columns = ['workclass', 'education', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'sex',\n",
        "    'native_country']\n",
        "    numerical_columns = ['age', 'capital_gain',\n",
        "    'capital_loss', 'hours_per_week']\n",
        "    column_transformer = make_column_transformer(\n",
        "    (OrdinalEncoder(), categorical_columns),\n",
        "    (StandardScaler(), numerical_columns),\n",
        "    )\n",
        "    self.y = LabelEncoder().fit_transform(df['income']).astype(float)\n",
        "    self.X = column_transformer.fit_transform(df)\n",
        "    self.X = Normalizer().fit_transform(self.X)\n",
        "    def __len__(self):\n",
        "    return len(self.y)"
      ],
      "metadata": {
        "id": "T-R9AzXtRA9p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}