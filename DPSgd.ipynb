{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaJaYMbVR92/dyk9lBv6RM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghosh-sarbajit/DifferentialPrivacy/blob/main/DPSgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uisKALJk-pAO"
      },
      "outputs": [],
      "source": [
        "!pip install opacus\n",
        "!pip install opendp==0.11\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHAPTER 9 Differentially Private Machine Learning (219p)"
      ],
      "metadata": {
        "id": "fCFeCh6u3icD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentially Private Gradient\n"
      ],
      "metadata": {
        "id": "Z76n2yn63ie1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import opendp.prelude as dp"
      ],
      "metadata": {
        "id": "2NIB12aRTtrF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_nabla_loss_i(w):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    w_0, w_1 = w\n",
        "    def f_compute_grads(data):\n",
        "        x, y = data[np.newaxis].T\n",
        "        y_hat = w_0 + w_1 * x # forward pass y^ = f(x)\n",
        "        return (y_hat - y) * np.column_stack([np.ones(x.size), x])\n",
        "    space = dp.numpy.array2_domain(T=float), dp.symmetric_distance()\n",
        "    return dp.t.make_user_transformation(\n",
        "        *space, *space, f_compute_grads,\n",
        "        stability_map=lambda b_in: b_in)"
      ],
      "metadata": {
        "id": "vRQzb1fOTCoZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHAPTER 3 Stable Transformations 79p\n",
        "def make_np_sum(norm, p, origin=None):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    assert norm >= 0, \"norm must not be negative\"\n",
        "    # assume the origin is at zero if not specified\n",
        "    origin = 0.0 if origin is None else origin\n",
        "    #    C = ||O||_p    + R\n",
        "    constant = np.linalg.norm(np.atleast_1d(origin), ord=p) + norm\n",
        "    return dp.t.make_user_transformation(input_domain=dp.numpy.array2_domain(norm=norm, p=p, origin=origin),\n",
        "        input_metric=dp.symmetric_distance(),\n",
        "        output_domain=dp.vector_domain(dp.atom_domain(T=float)),\n",
        "        output_metric={1: dp.l1_distance, 2: dp.l2_distance}[p](T=float),\n",
        "        function=lambda data: data.sum(axis=0),\n",
        "        stability_map=lambda b_in: b_in * constant)"
      ],
      "metadata": {
        "id": "BYRqUMgW3-9E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHAPTER 3 Stable Transformations 80p\n",
        "def make_np_clamp(norm, p, origin=None):\n",
        "    dp.assert_features(\"contrib\", \"floating-point\")\n",
        "    assert norm >= 0., \"norm must not be negative\"\n",
        "    # assume the origin is at zero if not specified\n",
        "    origin = 0.0 if origin is None else origin\n",
        "\n",
        "    def clamp_row_norms(data):\n",
        "        data = data.copy()\n",
        "        # shift the data around zero\n",
        "        data -= origin\n",
        "\n",
        "        # compute the p-norm of each row\n",
        "        row_norms = np.linalg.norm(data, ord=p, axis=1, keepdims=True)\n",
        "        # scale each row down to have norm at most 1\n",
        "        data /= np.maximum(row_norms / norm, 1)\n",
        "\n",
        "        # shift the normed data around zero back to `origin`\n",
        "        data += origin\n",
        "        return data\n",
        "\n",
        "    return dp.t.make_user_transformation(\n",
        "    input_domain= dp.numpy.array2_domain (T=float), # input data is unconstrained\n",
        "    input_metric=dp.symmetric_distance(),\n",
        "    output_domain=dp.numpy.array2_domain(norm=norm, p=p, origin=origin),\n",
        "    output_metric=dp.symmetric_distance(),\n",
        "    function=clamp_row_norms,\n",
        "    stability_map=lambda b_in: b_in) # norm clamping is 1-stable row-by-row"
      ],
      "metadata": {
        "id": "fleKZcHA4AA0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 100000\n",
        "# public metadata\n",
        "# \"load\" the data\n",
        "x = np.random.uniform(-5, 5, size=N)\n",
        "y = 3 + 2 * x + np.random.normal(size=x.size)\n",
        "data = np.column_stack((x, y))\n",
        "max_contributions = 1"
      ],
      "metadata": {
        "id": "JYmIJRgST79u"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model hyperparameters\n",
        "w = np.array([0.0, 0.0]) # initial choice of params\n",
        "gamma, num_steps = 0.3, 20\n",
        "norm = 2. # assumes most grads have magnitude lte 2\n",
        "noise_std = 100."
      ],
      "metadata": {
        "id": "_RjFDR8oaXEK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AFELEnI8vWXq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFDnEPoWvpIL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/opendp/opendp/discussions/304\n",
        "from opendp.mod import enable_features\n",
        "enable_features(\"contrib\")\n",
        "enable_features(\"floating-point\")\n",
        "enable_features(\"honest-but-curious\")"
      ],
      "metadata": {
        "id": "M-YLZy9syO3G"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_meas = make_np_clamp(norm, p=2) >> \\\n",
        "    make_np_sum(norm, p=2) >> \\\n",
        "    dp.m.then_gaussian(scale=noise_std) >> \\\n",
        "    np.array # a postprocessor- load into a numpy array"
      ],
      "metadata": {
        "id": "aYjhTzSyaRKg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meas_comp = dp.c.make_sequential_composition(\n",
        "    input_domain=sum_meas.input_domain,\n",
        "    input_metric=sum_meas.input_metric,\n",
        "    output_measure=dp.zero_concentrated_divergence(T=float),\n",
        "    d_in=max_contributions,\n",
        "    d_mids=[sum_meas.map(max_contributions)] * num_steps\n",
        ")\n",
        "# qbl is an instance of the compositor that allows up to `num_steps` queries\n",
        "qbl = meas_comp(data)\n",
        "# now the only way to access the data is through the compositor\n",
        "del data"
      ],
      "metadata": {
        "id": "Y-QQrS3UaRUw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(meas_comp.map(max_contributions)) # -> 0.004 = ρ\n",
        "εδ_curve = dp.c.make_zCDP_to_approxDP(meas_comp).map(max_contributions)\n",
        "print(εδ_curve.epsilon(1e-8)) # -> (0.4659, 1e-8) = (ε, δ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnAeC47Y2FYn",
        "outputId": "0538e56e-4790-49d7-f6d0-08aa4c2f8779"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.004000000000000002\n",
            "0.46596519652756707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(num_steps):\n",
        "    # make a mechanism that computes the gradient\n",
        "    meas_nabla_loss = make_nabla_loss_i(w) >> sum_meas\n",
        "    # privately release the gradient by querying the compositor\n",
        "    w -= gamma * 2 / N * qbl(meas_nabla_loss)"
      ],
      "metadata": {
        "id": "vUO8FnQOa1Rk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"params:\", w)"
      ],
      "metadata": {
        "id": "vwDz97vjaRaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4f1fbd-00bb-45e0-9b02-5a98298e79ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params: [2.99596024 1.9970563 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Batching (DP-SGD)"
      ],
      "metadata": {
        "id": "fD5WnkeMaQZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, \\\n",
        "OrdinalEncoder, Normalizer\n",
        "from opacus import PrivacyEngine"
      ],
      "metadata": {
        "id": "ROc1yj9GKAqn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdultDataSet(Dataset):\n",
        "    def __init__(self, adult_data_file):\n",
        "    header = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
        "    'marital_status', 'occupation', 'relationship',\n",
        "    'race', 'sex', 'capital_gain', 'capital_loss',\n",
        "    'hours_per_week', 'native_country', 'income']\n",
        "    df = pd.read_csv(adult_data_file, header=None, names=header,\n",
        "    sep=',\\\\s', na_values=['?'], engine='python')\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['income'] = df['income'].apply(lambda x: x.replace('.', ''))\n",
        "    categorical_columns = ['workclass', 'education', 'marital_status',\n",
        "    'occupation', 'relationship', 'race', 'sex',\n",
        "    'native_country']\n",
        "    numerical_columns = ['age', 'capital_gain',\n",
        "    'capital_loss', 'hours_per_week']\n",
        "    column_transformer = make_column_transformer(\n",
        "    (OrdinalEncoder(), categorical_columns),\n",
        "    (StandardScaler(), numerical_columns),\n",
        "    )\n",
        "    self.y = LabelEncoder().fit_transform(df['income']).astype(float)\n",
        "    self.X = column_transformer.fit_transform(df)\n",
        "    self.X = Normalizer().fit_transform(self.X)\n",
        "    def __len__(self):\n",
        "    return len(self.y)"
      ],
      "metadata": {
        "id": "T-R9AzXtRA9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "eb167c04-a4c8-4c8d-f677-432e7ec0bd9d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 2 (<ipython-input-31-022f39148bbe>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-022f39148bbe>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    header = ['age', 'workclass', 'fnlwgt', 'education', 'education_num',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 2\n"
          ]
        }
      ]
    }
  ]
}